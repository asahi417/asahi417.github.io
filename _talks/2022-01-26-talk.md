---
title: "Toward a Better Understanding of Relational Knowledge in Language Models"
collection: talks
type: "Research Seminar"
permalink: /talks/2022-01-26-talk
venue: "NLP colloquium (Japanese)"
date: 2022-01-26
location: "Tokyo, Japan (Remote)"
---

This is an invited talk at [NLP Colloquium](https://nlp-colloquium-jp.github.io/) about relational knowledge representation of language models including the following papers.
- [Ushio, et al. "Distilling Relation Embeddings from Pretrained Language Models" 2021](https://aclanthology.org/2021.acl-long.280/)
- [Ushio, et al. "BERT is to NLP what AlexNet is to CV: Can Pre-Trained Language Models Identify Analogies?" 2021](https://aclanthology.org/2021.acl-long.280/)

The talk is being recoded and shared [here](https://nlp-colloquium-jp.github.io/schedule/2022-01-26_asahi-ushio/).

<iframe src="//www.slideshare.net/slideshow/embed_code/key/9RLRoFQOy0Yz3l" width="595" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe> <div style="margin-bottom:5px"> <strong> <a href="//asahiushio.com/publications/2022-01nlpcolloquiumjapanesetowardabetterunderstandingofrelationalknowledgeinlanguagemodels-221002165428-9393673d.pdf" title="2022-01, NLP colloquium (Japanese), Toward a Better Understanding of Relational Knowledge in Language Models" target="_blank">2022-01, NLP colloquium (Japanese), Toward a Better Understanding of Relational Knowledge in Language Models</a> </strong> </div>
